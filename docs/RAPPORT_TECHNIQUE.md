# ğŸ“„ Rapport Technique - HealthAI Coach Backend

## Projet MSPR TPRE501 - Bloc E6.1

**Ã‰quipe projet** : MSPR TPRE501  
**Date** : 2025  
**Version** : 1.0

---

## 1. Contexte et Objectifs

### 1.1. Contexte

HealthAI Coach est une startup franÃ§aise positionnÃ©e sur le marchÃ© de la santÃ© connectÃ©e et du coaching personnalisÃ©. L'entreprise souhaite mettre en place une infrastructure technique robuste pour collecter, transformer et stocker des donnÃ©es hÃ©tÃ©rogÃ¨nes provenant de sources variÃ©es (APIs publiques, datasets open data, fichiers simulÃ©s).

### 1.2. Objectifs

L'objectif principal Ã©tait de concevoir, dÃ©velopper et livrer le backend mÃ©tier de la future plateforme HealthAI Coach, incluant :

- Un systÃ¨me de collecte automatisÃ©e capable d'intÃ©grer diffÃ©rentes sources de donnÃ©es
- Un processus de transformation et de nettoyage garantissant l'exploitabilitÃ© des donnÃ©es
- Une base de donnÃ©es relationnelle adaptÃ©e aux besoins de l'entreprise
- Une API REST permettant de consulter et d'exploiter les donnÃ©es consolidÃ©es
- Une interface de visualisation accessible permettant de suivre les indicateurs clÃ©s

---

## 2. Choix Technologiques

### 2.1. Architecture GÃ©nÃ©rale

L'architecture choisie suit une approche modulaire et microservices, permettant une Ã©volution future et une maintenance facilitÃ©e :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ETL       â”‚â”€â”€â”€â”€â–¶â”‚  Supabase   â”‚â—€â”€â”€â”€â”€â”‚    API      â”‚
â”‚  Pipeline   â”‚     â”‚ (PostgreSQL)â”‚     â”‚  (FastAPI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚  Streamlit  â”‚
                                         â”‚  Interface  â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2. Technologies Retenues

#### 2.2.1. Base de DonnÃ©es : Supabase (PostgreSQL)

**Justification** :
- PostgreSQL offre une robustesse et des performances adaptÃ©es aux besoins relationnels
- Supabase fournit une infrastructure hÃ©bergÃ©e avec authentification intÃ©grÃ©e
- Support natif des types de donnÃ©es complexes (arrays, JSON)
- Compatible avec les outils standards (SQL, ORM)

**Avantages** :
- DÃ©ploiement rapide sans gestion d'infrastructure
- API REST automatique
- Row Level Security (RLS) pour la sÃ©curitÃ©
- Interface d'administration intÃ©grÃ©e

#### 2.2.2. API : FastAPI

**Justification** :
- Framework moderne et performant (basÃ© sur Starlette et Pydantic)
- Documentation OpenAPI automatique (Swagger UI)
- Validation des donnÃ©es intÃ©grÃ©e via Pydantic
- Support asynchrone natif
- Type hints pour une meilleure maintenabilitÃ©

**Avantages** :
- DÃ©veloppement rapide
- Documentation interactive automatique
- Validation automatique des entrÃ©es/sorties
- Performance Ã©levÃ©e

#### 2.2.3. Interface Administration : Streamlit

**Justification** :
- Framework Python simple pour crÃ©er des interfaces web rapidement
- IntÃ©gration native avec Pandas et les bibliothÃ¨ques de visualisation
- Pas besoin de connaissances frontend (HTML/CSS/JS)
- DÃ©ploiement facile

**Avantages** :
- DÃ©veloppement rapide d'interfaces interactives
- Support natif des graphiques (Plotly, Matplotlib)
- Compatible avec l'Ã©cosystÃ¨me Python existant
- Accessible pour les Ã©quipes non techniques

#### 2.2.4. Pipeline ETL : Python + Pandas

**Justification** :
- Pandas est la bibliothÃ¨que standard pour la manipulation de donnÃ©es en Python
- Support natif de nombreux formats (CSV, JSON, Excel, API)
- Fonctions de nettoyage et transformation puissantes
- IntÃ©gration facile avec les autres composants

**Avantages** :
- FlexibilitÃ© dans le traitement des donnÃ©es
- Large communautÃ© et documentation
- Performance sur les datasets moyens
- CompatibilitÃ© avec l'Ã©cosystÃ¨me Python

#### 2.2.5. Orchestration : Docker & Docker Compose

**Justification** :
- Standardisation de l'environnement de dÃ©veloppement et production
- Isolation des services
- FacilitÃ© de dÃ©ploiement
- ReproducibilitÃ©

**Avantages** :
- Environnement reproductible
- DÃ©ploiement simplifiÃ©
- Isolation des dÃ©pendances
- Compatible avec la plupart des plateformes cloud

---

## 3. Architecture DÃ©taillÃ©e

### 3.1. ModÃ¨le de DonnÃ©es

Le modÃ¨le de donnÃ©es suit une approche relationnelle classique avec les entitÃ©s suivantes :

- **Utilisateurs** : Profils des utilisateurs de la plateforme
- **Objectifs** : Objectifs personnalisÃ©s des utilisateurs
- **Aliments** : Base nutritionnelle
- **Exercices** : Catalogue d'exercices sportifs
- **Journal alimentaire** : Suivi nutritionnel quotidien
- **Sessions sport** : Sessions d'entraÃ®nement
- **Mesures biomÃ©triques** : DonnÃ©es de santÃ© (poids, frÃ©quence cardiaque, etc.)

Le ModÃ¨le Conceptuel de DonnÃ©es (MCD) et le ModÃ¨le Logique de DonnÃ©es (MLD) sont documentÃ©s dans `docs/MCD.txt` et `docs/MLD.txt`.

### 3.2. Pipeline ETL

Le pipeline ETL suit l'architecture classique Extract-Transform-Load :

1. **Extract** : Extraction depuis diverses sources (API, CSV, JSON)
2. **Transform** : Nettoyage, normalisation, validation
3. **Load** : Chargement dans Supabase avec gestion des conflits

Le pipeline est planifiÃ© via APScheduler pour s'exÃ©cuter automatiquement (par dÃ©faut toutes les 6 heures).

### 3.3. API REST

L'API FastAPI expose des endpoints CRUD pour toutes les entitÃ©s :

- `GET /api/v1/{entity}` : Liste avec pagination et filtres
- `GET /api/v1/{entity}/{id}` : DÃ©tails d'un enregistrement
- `POST /api/v1/{entity}` : CrÃ©ation
- `PUT /api/v1/{entity}/{id}` : Mise Ã  jour
- `DELETE /api/v1/{entity}/{id}` : Suppression

La documentation OpenAPI est accessible via `/docs`.

### 3.4. Interface Streamlit

L'interface Streamlit propose :

- **Accueil** : Vue d'ensemble avec statistiques
- **Dashboard** : Graphiques interactifs et KPIs business
- **Gestion CRUD** : Exercices, Utilisateurs, Aliments
- **Configuration** : Outils de nettoyage, mÃ©triques de qualitÃ©, export

---

## 4. RÃ©sultats Obtenus

### 4.1. FonctionnalitÃ©s ImplÃ©mentÃ©es

âœ… **Pipeline ETL opÃ©rationnel** :
- Extraction depuis ExerciseDB API (200+ exercices)
- Extraction depuis fichiers CSV (aliments)
- Transformation et nettoyage automatique
- Chargement dans Supabase avec gestion des conflits

âœ… **Base de donnÃ©es relationnelle** :
- 11 tables crÃ©Ã©es selon le MLD
- Relations et contraintes dÃ©finies
- Index pour optimiser les performances

âœ… **API REST complÃ¨te** :
- Endpoints CRUD pour toutes les entitÃ©s
- Documentation OpenAPI interactive
- Validation des donnÃ©es via Pydantic
- Gestion des erreurs

âœ… **Interface d'administration** :
- Dashboard avec visualisations interactives
- Gestion CRUD complÃ¨te
- Outils de nettoyage interactifs
- Export des donnÃ©es (CSV/JSON)
- MÃ©triques de qualitÃ©

### 4.2. MÃ©triques de Performance

- **Temps d'exÃ©cution ETL** : ~30-60 secondes pour 200 exercices
- **Temps de rÃ©ponse API** : < 200ms pour la plupart des requÃªtes
- **Volume de donnÃ©es** : 200+ exercices, 4+ aliments, 2+ utilisateurs de test
- **Taux de rÃ©ussite ETL** : > 95% (gestion des erreurs par source)

### 4.3. QualitÃ© des DonnÃ©es

- **Taux de doublons dÃ©tectÃ©s** : < 5%
- **Taux de valeurs manquantes** : < 10%
- **Taux de validation** : > 90% des donnÃ©es passent la validation

---

## 5. DifficultÃ©s RencontrÃ©es et Solutions

### 5.1. Gestion des Types de DonnÃ©es Complexes

**ProblÃ¨me** : Les donnÃ©es d'exercices contenaient des listes (groupes musculaires, Ã©quipements) qui n'Ã©taient pas directement compatibles avec PostgreSQL.

**Solution** : Conversion des listes en chaÃ®nes de caractÃ¨res ou utilisation de types array PostgreSQL selon le besoin.

### 5.2. Gestion des Conflits lors du Chargement

**ProblÃ¨me** : Les donnÃ©es extraites pouvaient contenir des doublons, causant des erreurs lors de l'insertion.

**Solution** : ImplÃ©mentation d'un systÃ¨me d'upsert basÃ© sur des clÃ©s uniques (nom pour exercices/aliments, email pour utilisateurs).

### 5.3. Validation des DonnÃ©es HÃ©tÃ©rogÃ¨nes

**ProblÃ¨me** : Les sources de donnÃ©es avaient des formats diffÃ©rents (colonnes, noms, types).

**Solution** : CrÃ©ation de fonctions de transformation spÃ©cifiques par source, avec normalisation vers un schÃ©ma commun.

### 5.4. Configuration des Variables d'Environnement

**ProblÃ¨me** : Les variables d'environnement n'Ã©taient pas toujours chargÃ©es correctement selon le contexte d'exÃ©cution.

**Solution** : Utilisation de chemins absolus pour le fichier `.env` et validation explicite des variables requises.

---

## 6. Perspectives d'Ã‰volution

### 6.1. Court Terme

- **Authentification complÃ¨te** : ImplÃ©mentation de l'authentification JWT avec Supabase Auth
- **Row Level Security** : Activation de RLS dans Supabase pour la sÃ©curitÃ© des donnÃ©es
- **Tests automatisÃ©s** : Ajout de tests unitaires et d'intÃ©gration
- **Pages Streamlit manquantes** : Journal alimentaire, Sessions sport, Mesures biomÃ©triques

### 6.2. Moyen Terme

- **Modules IA** : IntÃ©gration de modÃ¨les de recommandation personnalisÃ©s
- **Monitoring** : Ajout de mÃ©triques et alertes (Prometheus, Grafana)
- **Cache** : Mise en place d'un systÃ¨me de cache (Redis) pour amÃ©liorer les performances
- **API GraphQL** : Alternative Ã  REST pour des requÃªtes plus flexibles

### 6.3. Long Terme

- **ScalabilitÃ©** : Migration vers une architecture microservices complÃ¨te
- **Data Warehouse** : Mise en place d'un entrepÃ´t de donnÃ©es pour l'analytics avancÃ©
- **Streaming** : IntÃ©gration de donnÃ©es en temps rÃ©el (Kafka, Apache Flink)
- **Multi-tenant** : Support de plusieurs clients B2B avec isolation des donnÃ©es

---

## 7. Conclusion

Le projet a permis de mettre en place un backend mÃ©tier complet et fonctionnel pour HealthAI Coach. L'architecture choisie est modulaire, Ã©volutive et respecte les bonnes pratiques de dÃ©veloppement. Les fonctionnalitÃ©s de base sont opÃ©rationnelles et prÃªtes pour l'intÃ©gration dans l'Ã©cosystÃ¨me global de la startup.

Les principaux dÃ©fis ont Ã©tÃ© relevÃ©s avec succÃ¨s, notamment la gestion de donnÃ©es hÃ©tÃ©rogÃ¨nes et la mise en place d'un pipeline ETL robuste. Les perspectives d'Ã©volution sont nombreuses et permettront d'enrichir progressivement la plateforme.

---

## 8. Annexes

### 8.1. Structure du Projet

```
MSPR1/
â”œâ”€â”€ api/                    # Service FastAPI
â”œâ”€â”€ streamlit/              # Interface d'administration
â”œâ”€â”€ etl/                    # Pipeline ETL
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ test/                   # Tests
â””â”€â”€ docker-compose.yml      # Orchestration
```

### 8.2. Documentation ComplÃ©mentaire

- `docs/RAPPORT_INVENTAIRE_SOURCES.md` : Inventaire des sources de donnÃ©es
- `docs/DIAGRAMME_FLUX_DONNEES.md` : Diagramme des flux de donnÃ©es
- `docs/API_ENDPOINTS.md` : Documentation des endpoints API
- `docs/MCD.txt` et `docs/MLD.txt` : ModÃ¨les de donnÃ©es

### 8.3. Technologies UtilisÃ©es

- **Python** : 3.10+
- **FastAPI** : 0.104.1
- **Streamlit** : 1.28.0
- **Pandas** : 2.1.0
- **Supabase** : 2.0.3
- **PostgreSQL** : 15+ (via Supabase)
- **Docker** : 24+
- **Docker Compose** : 2.20+

---

**Document gÃ©nÃ©rÃ© le** : 2025  
**Version** : 1.0  
**Auteur** : Ã‰quipe MSPR TPRE501

