# üìä Rapport d'Inventaire des Sources de Donn√©es

## HealthAI Coach - Backend M√©tier

**Date de cr√©ation** : 2025  
**Version** : 1.0  
**√âquipe projet** : MSPR TPRE501

---

## 1. Introduction

Ce document recense toutes les sources de donn√©es utilis√©es dans le projet HealthAI Coach, en pr√©cisant leur origine, leur format, leur fr√©quence de mise √† jour et les r√®gles appliqu√©es pour en assurer la qualit√©.

---

## 2. Sources de Donn√©es Externes

### 2.1. ExerciseDB API (Exercices Sportifs)

**Origine** :  
- **Source principale** : Repository GitHub public `yuhonas/free-exercise-db`
- **URL** : `https://raw.githubusercontent.com/yuhonas/free-exercise-db/main/dist/exercises.json`
- **Source alternative** : RapidAPI ExerciseDB (si cl√© API disponible)
- **Type** : Open Data / API publique

**Format** :  
- **Format de donn√©es** : JSON
- **Structure** : Tableau d'objets JSON
- **Encodage** : UTF-8

**Fr√©quence de mise √† jour** :  
- **Mise √† jour source** : Irr√©guli√®re (d√©pend du mainteneur GitHub)
- **Fr√©quence d'ingestion** : Toutes les 6 heures (configurable via `ETL_SCHEDULE`)
- **Strat√©gie** : Upsert bas√© sur le nom de l'exercice pour √©viter les doublons

**Volume** :  
- **Nombre d'exercices disponibles** : ~1300+ exercices
- **Volume ing√©r√©** : 200 exercices par ex√©cution (limite configurable)
- **Taille moyenne** : ~50-100 KB par extraction

**R√®gles de qualit√© appliqu√©es** :  
1. **Validation des champs obligatoires** :
   - `nom` : Requis, non vide, string
   - `type` : Normalis√© (force, cardio, flexibilite, autre)
   - `niveau` : Normalis√© (debutant, intermediaire, avance)
   - `equipement` : Normalis√© (aucun, halt√®res, barre, etc.)

2. **Nettoyage** :
   - Suppression des doublons bas√©e sur le nom
   - Normalisation des valeurs de type, niveau, √©quipement
   - Conversion des listes en cha√Ænes de caract√®res pour compatibilit√© PostgreSQL
   - Gestion des valeurs nulles

3. **Transformation** :
   - Mapping des champs API vers le sch√©ma base de donn√©es :
     - `name` ‚Üí `nom`
     - `type` ‚Üí `type` (normalis√©)
     - `muscle` ‚Üí `groupe_musculaire`
     - `difficulty` ‚Üí `niveau` (normalis√©)
     - `equipment` ‚Üí `equipement` (normalis√©)
     - `instructions` ‚Üí `instructions`
   - Source marqu√©e comme "ExerciseDB API"

**Justification du choix** :  
- Source gratuite et accessible sans authentification
- Donn√©es structur√©es et compl√®tes (nom, type, groupe musculaire, niveau, √©quipement, instructions)
- Volume important permettant de couvrir une large gamme d'exercices
- Format JSON facilement exploitable
- Alternative disponible via RapidAPI si besoin d'acc√®s premium

---

### 2.2. Datasets Kaggle (Nutrition)

**Origine** :  
- **Source 1** : Daily Food & Nutrition Dataset
  - **URL** : `https://www.kaggle.com/datasets/adilshamim8/daily-food-and-nutrition-dataset`
  - **Auteur** : adilshamim8
  - **Type** : Open Data (Kaggle)

- **Source 2** : Diet Recommendations Dataset
  - **URL** : `https://www.kaggle.com/datasets/ziya07/diet-recommendations-dataset`
  - **Auteur** : ziya07
  - **Type** : Open Data (Kaggle)

**Format** :  
- **Format de donn√©es** : CSV
- **S√©parateur** : Virgule (`,`)
- **Encodage** : UTF-8
- **En-t√™tes** : Pr√©sents (premi√®re ligne)

**Fr√©quence de mise √† jour** :  
- **Mise √† jour source** : Statique (datasets Kaggle)
- **Fr√©quence d'ingestion** : Toutes les 6 heures (configurable)
- **Strat√©gie** : Upsert bas√© sur le nom de l'aliment

**Volume** :  
- **Volume estim√©** : Variable selon le dataset (100-1000+ aliments)
- **Taille moyenne** : 1-5 MB par fichier CSV

**R√®gles de qualit√© appliqu√©es** :  
1. **Validation des champs obligatoires** :
   - `nom` : Requis, non vide
   - `calories` : Requis, num√©rique, >= 0

2. **Nettoyage** :
   - Suppression des doublons
   - Normalisation des noms d'aliments (minuscules, suppression accents optionnelle)
   - Validation des valeurs nutritionnelles (calories, prot√©ines, glucides, lipides >= 0)
   - Gestion des valeurs manquantes (remplacement par 0 pour valeurs num√©riques)

3. **Transformation** :
   - Mapping des colonnes selon le format source :
     - Standardisation des noms de colonnes
     - Conversion des unit√©s (g, mg, etc.)
     - Normalisation des valeurs nutritionnelles
   - Source marqu√©e selon le dataset d'origine

**Justification du choix** :  
- Donn√©es nutritionnelles compl√®tes et v√©rifi√©es
- Format CSV standardis√© et facilement exploitable
- Volume important permettant de couvrir une large gamme d'aliments
- Donn√©es open source accessibles gratuitement
- Compatibilit√© avec les outils ETL standards (Pandas)

---

### 2.3. Donn√©es Utilisateurs Simul√©es

**Origine** :  
- **Source** : G√©n√©ration interne / Simulation
- **Type** : Donn√©es de test g√©n√©r√©es par le pipeline ETL

**Format** :  
- **Format de donn√©es** : G√©n√©ration programmatique (Python)
- **Structure** : Dictionnaires Python convertis en DataFrame

**Fr√©quence de mise √† jour** :  
- **G√©n√©ration** : √Ä chaque ex√©cution du pipeline ETL (si donn√©es manquantes)
- **Strat√©gie** : Insertion uniquement si utilisateurs de test absents

**Volume** :  
- **Nombre d'utilisateurs de test** : 2-5 utilisateurs
- **Objectif** : Permettre les tests et d√©monstrations

**R√®gles de qualit√© appliqu√©es** :  
1. **Validation** :
   - Email : Format valide (validation regex)
   - √Çge : Entre 1 et 150 ans
   - Poids : > 0 kg
   - Taille : > 0 cm
   - Objectifs : Liste de strings valides

2. **Nettoyage** :
   - Normalisation des emails (minuscules)
   - Validation des types d'abonnement (freemium, premium, premium+, B2B)
   - Formatage des objectifs en tableau PostgreSQL

**Justification du choix** :  
- N√©cessaire pour les tests et d√©monstrations
- Permet de valider le fonctionnement complet du syst√®me
- Donn√©es r√©alistes mais fictives (conformit√© RGPD)

---

## 3. Sources de Donn√©es Internes

### 3.1. Base de Donn√©es Supabase (PostgreSQL)

**Origine** :  
- **Source** : Base de donn√©es relationnelle Supabase
- **Type** : Base de donn√©es PostgreSQL h√©berg√©e

**Format** :  
- **Format de donn√©es** : PostgreSQL (relationnel)
- **Sch√©ma** : D√©fini selon le MLD (Mod√®le Logique de Donn√©es)
- **Tables principales** :
  - `utilisateurs`
  - `objectifs`
  - `aliments`
  - `exercices`
  - `journal_alimentaire`
  - `sessions_sport`
  - `session_exercices`
  - `mesures_biometriques`
  - `progressions`

**Fr√©quence de mise √† jour** :  
- **Mise √† jour** : Continue (via API et ETL)
- **Fr√©quence d'ingestion** : En temps r√©el (API) + Batch (ETL toutes les 6h)

**Volume** :  
- **Volume actuel** : Variable selon les donn√©es ing√©r√©es
- **Capacit√©** : Illimit√©e (selon plan Supabase)

**R√®gles de qualit√© appliqu√©es** :  
1. **Contraintes de base de donn√©es** :
   - Cl√©s primaires (UUID)
   - Cl√©s √©trang√®res (int√©grit√© r√©f√©rentielle)
   - Contraintes UNIQUE (emails, noms d'exercices/aliments)
   - Contraintes CHECK (valeurs num√©riques >= 0)

2. **Validation applicative** :
   - Validation via Pydantic schemas (API)
   - Validation via Pandas (ETL)
   - Gestion des erreurs et rollback en cas d'√©chec

---

## 4. Diagramme des Flux de Donn√©es

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SOURCES DE DONN√âES EXTERNES                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  ExerciseDB API  ‚îÇ  ‚îÇ  Kaggle Datasets ‚îÇ  ‚îÇ  Donn√©es     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (JSON)          ‚îÇ  ‚îÇ  (CSV)           ‚îÇ  ‚îÇ  Simul√©es    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ                     ‚îÇ                    ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                     ‚îÇ                    ‚îÇ
            ‚ñº                     ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE ETL (EXTRACT)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ extract_exercises_from_exercisedb()                         ‚îÇ
‚îÇ  ‚Ä¢ extract_from_csv()                                          ‚îÇ
‚îÇ  ‚Ä¢ extract_from_excel()                                        ‚îÇ
‚îÇ  ‚Ä¢ extract_from_api()                                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PIPELINE ETL (TRANSFORM & CLEAN)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ transform_exercises_from_exercisedb()                        ‚îÇ
‚îÇ  ‚Ä¢ transform_foods_from_csv()                                   ‚îÇ
‚îÇ  ‚Ä¢ clean_data()                                                 ‚îÇ
‚îÇ    - Suppression doublons                                       ‚îÇ
‚îÇ    - Normalisation valeurs                                      ‚îÇ
‚îÇ    - Validation types                                           ‚îÇ
‚îÇ  ‚Ä¢ validate_data()                                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PIPELINE ETL (LOAD)                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ SupabaseLoader.upsert_dataframe()                           ‚îÇ
‚îÇ  ‚Ä¢ Gestion des conflits (on_conflict)                           ‚îÇ
‚îÇ  ‚Ä¢ Logging des erreurs                                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         BASE DE DONN√âES SUPABASE (PostgreSQL)                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  Tables:                                                        ‚îÇ
‚îÇ  ‚Ä¢ utilisateurs                                                 ‚îÇ
‚îÇ  ‚Ä¢ objectifs                                                    ‚îÇ
‚îÇ  ‚Ä¢ aliments                                                     ‚îÇ
‚îÇ  ‚Ä¢ exercices                                                    ‚îÇ
‚îÇ  ‚Ä¢ journal_alimentaire                                          ‚îÇ
‚îÇ  ‚Ä¢ sessions_sport                                               ‚îÇ
‚îÇ  ‚Ä¢ mesures_biometriques                                         ‚îÇ
‚îÇ  ‚Ä¢ ...                                                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    API REST (FastAPI)                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  Endpoints CRUD:                                                ‚îÇ
‚îÇ  ‚Ä¢ GET    /api/v1/utilisateurs                                  ‚îÇ
‚îÇ  ‚Ä¢ POST   /api/v1/utilisateurs                                  ‚îÇ
‚îÇ  ‚Ä¢ PUT    /api/v1/utilisateurs/{id}                             ‚îÇ
‚îÇ  ‚Ä¢ DELETE /api/v1/utilisateurs/{id}                             ‚îÇ
‚îÇ  ‚Ä¢ ... (aliments, exercices, journal, sessions, mesures)        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         INTERFACE ADMINISTRATION (Streamlit)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Dashboard avec visualisations                                ‚îÇ
‚îÇ  ‚Ä¢ Outils de nettoyage interactifs                              ‚îÇ
‚îÇ  ‚Ä¢ Export des donn√©es (JSON/CSV)                                ‚îÇ
‚îÇ  ‚Ä¢ Gestion des donn√©es (CRUD)                                   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 5. R√®gles de Qualit√© Globales

### 5.1. Validation des Donn√©es

1. **Validation des types** :
   - V√©rification des types de donn√©es (string, int, float, date)
   - Conversion automatique lorsque possible
   - Rejet des donn√©es non convertibles

2. **Validation des contraintes** :
   - Valeurs num√©riques >= 0 (calories, poids, etc.)
   - Formats d'email valides
   - Dates dans un format coh√©rent
   - Longueurs de cha√Ænes respect√©es

3. **Validation de compl√©tude** :
   - Champs obligatoires pr√©sents
   - Gestion des valeurs nulles selon les r√®gles m√©tier

### 5.2. Nettoyage des Donn√©es

1. **Suppression des doublons** :
   - Bas√©e sur des cl√©s uniques (nom, email, etc.)
   - Conservation de la premi√®re occurrence

2. **Normalisation** :
   - Normalisation des cha√Ænes (minuscules, suppression espaces)
   - Normalisation des valeurs √©num√©r√©es (type, niveau, etc.)
   - Conversion des unit√©s (standardisation)

3. **Gestion des valeurs manquantes** :
   - Remplacement par valeurs par d√©faut (0 pour num√©riques)
   - Conservation des NULL pour champs optionnels
   - Logging des valeurs manquantes pour analyse

### 5.3. Gestion des Erreurs

1. **Logging** :
   - Logging de toutes les erreurs avec contexte
   - Niveaux de log (INFO, WARNING, ERROR)
   - Tra√ßabilit√© compl√®te des op√©rations

2. **R√©cup√©ration** :
   - Gestion des erreurs par source (une source en √©chec n'emp√™che pas les autres)
   - Rollback en cas d'erreur critique
   - Notification des √©checs

---

## 6. M√©triques de Qualit√©

### 6.1. Indicateurs Suivis

- **Taux de r√©ussite d'ingestion** : % de donn√©es ing√©r√©es avec succ√®s
- **Taux de doublons d√©tect√©s** : % de doublons identifi√©s et supprim√©s
- **Taux de valeurs manquantes** : % de valeurs manquantes par champ
- **Taux d'erreurs de validation** : % de donn√©es rejet√©es pour non-conformit√©
- **Temps d'ex√©cution ETL** : Dur√©e totale du pipeline

### 6.2. Tableau de Bord Qualit√©

Ces m√©triques sont disponibles dans l'interface Streamlit (section "Configuration" ‚Üí "Qualit√© des donn√©es").

---

## 7. Conclusion

Ce rapport d'inventaire recense toutes les sources de donn√©es utilis√©es dans le projet HealthAI Coach, avec leurs caract√©ristiques, leurs r√®gles de qualit√© et leur int√©gration dans le pipeline ETL. Les sources sont vari√©es (API, CSV, donn√©es simul√©es) et sont trait√©es de mani√®re automatis√©e et s√©curis√©e pour garantir la qualit√© et l'exploitabilit√© des donn√©es.

---

**Document g√©n√©r√© le** : 2025  
**Derni√®re mise √† jour** : 2025  
**Version** : 1.0

